{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML: Train \"the best\" Image Classification Multi-Label model for a 'Fridge items' dataset.\n",
    "\n",
    "**Requirements** - In order to benefit from this tutorial, you will need:\n",
    "- A basic understanding of Machine Learning\n",
    "- An Azure account with an active subscription. [Create an account for free](https://azure.microsoft.com/free/?WT.mc_id=A261C142F)\n",
    "- An Azure ML workspace. [Check this notebook for creating a workspace](../../../resources/workspace/workspace.ipynb) \n",
    "- A Compute Cluster. [Check this notebook to create a compute cluster](../../../resources/compute/compute.ipynb)\n",
    "- A python environment\n",
    "- Installed Azure Machine Learning Python SDK v2 - [install instructions](../../../README.md) - check the getting started section\n",
    "\n",
    "**Learning Objectives** - By the end of this tutorial, you should be able to:\n",
    "- Connect to your AML workspace from the Python SDK\n",
    "- Create an `AutoML Image Classification Multilabel Training Job` with the 'image_classification_multilabel()' factory-function.\n",
    "- Train the model using AmlCompute by submitting/running the AutoML training job\n",
    "- Obtaing the model and score predictions with it\n",
    "\n",
    "**Motivations** - This notebook explains how to setup and run an AutoML image classification-multilabel job. This is one of the nine ML-tasks supported by AutoML. Other ML-tasks are 'forecasting', 'classification', 'image object detection', 'nlp text classification', etc.\n",
    "\n",
    "In this notebook, we go over how you can use AutoML for training an Image Classification Multi-Label model. We will use a small dataset to train the model, demonstrate how you can tune hyperparameters of the model to optimize model performance and deploy the model to use in inference scenarios. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connect to Azure Machine Learning Workspace\n",
    "\n",
    "The [workspace](https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace) is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning. In this section we will connect to the workspace in which the job will be run.\n",
    "\n",
    "## 1.1. Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "gather": {
     "logged": 1634852261599
    }
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential,AzureCliCredential\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "from azure.ai.ml.automl import SearchSpace, ClassificationPrimaryMetrics\n",
    "from azure.ai.ml.sweep import (\n",
    "    Choice,\n",
    "    Uniform,\n",
    "    BanditPolicy,\n",
    ")\n",
    "\n",
    "from azure.ai.ml import automl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Configure workspace details and get a handle to the workspace\n",
    "\n",
    "To connect to a workspace, we need identifier parameters - a subscription, resource group and workspace name. We will use these details in the `MLClient` from `azure.ai.ml` to get a han\n",
    "dle to the required Azure Machine Learning workspace. We use the default [default azure authentication](https://docs.microsoft.com/en-us/python/api/azure-identity/azure.identity.defaultazurecredential?view=azure-python) for this tutorial. Check the [configuration notebook](../../configuration.ipynb) for more details on how to configure credentials and connect to a workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "try:\n",
    "    raise Exception\n",
    "    # Will check all different authentication options on system and try and use on of those\n",
    "    credential = DefaultAzureCredential(verbose=True)\n",
    "    # Check if given credential can get token successfully.\n",
    "    #print(credential.get_token())\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    # This will open a browser page for\n",
    "    credential = InteractiveBrowserCredential()\n",
    "    pass\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "credential = AzureCliCredential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1634852261744
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We could not find config.json in: . or in its parent directories. Please provide the full path to the config file or ensure that config.json exists in the parent directories.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ml_client = None\n",
    "try:\n",
    "    ml_client = MLClient.from_config(credential)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    subscription_id = \"3bef7a06-fecc-47fc-ba25-a7899d62e16c\"\n",
    "    resource_group = \"Mini-Tumors-Germany\"\n",
    "    workspace = \"Mini-Tumors-Workspace\"\n",
    "    ml_client = MLClient(credential, subscription_id, resource_group, workspace)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. MLTable with input Training Data\n",
    "\n",
    "In order to generate models for computer vision tasks with automated machine learning, you need to bring labeled image data as input for model training in the form of an MLTable. You can create an MLTable from labeled training data in JSONL format. If your labeled training data is in a different format (like, pascal VOC or COCO), you can use a conversion script to first convert it to JSONL, and then create an MLTable. Alternatively, you can use Azure Machine Learning's [data labeling tool](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-create-image-labeling-projects) to manually label images, and export the labeled data to use for training your AutoML model.\n",
    "\n",
    "In this notebook, we use a toy dataset called Fridge Objects, which consists of 128 images of 4 labels of beverage container {can, carton, milk bottle, water bottle} photos taken on different backgrounds. It also includes a labels file in .csv format. This is one of the most common data formats for Image Classification Multi-Label: one csv file that contains the mapping of labels to a folder of images.\n",
    "\n",
    "All images in this notebook are hosted in [this repository](https://github.com/microsoft/computervision-recipes) and are made available under the [MIT license](https://github.com/microsoft/computervision-recipes/blob/master/LICENSE).\n",
    "\n",
    "**NOTE:** In this PRIVATE PREVIEW we're defining the MLTable in a separate folder and .YAML file.\n",
    "In later versions, you'll be able to do it all in Python APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Upload the images to Datastore through an AML Data asset (URI Folder)\n",
    "\n",
    "In order to use the data for training in Azure ML, we upload it to our default Azure Blob Storage of our  Azure ML Workspace.\n",
    "\n",
    "[Check this notebook for AML data asset example](https://github.com/Azure/azureml-examples/blob/de54247989beee62d1fd89c2b6f1b89f49ef2f47/sdk/python/assets/data/data.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading converted (75.8 MBs): 100%|█| 75804395/75804395 [00:27<00:00, 2780869.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data({'skip_validation': False, 'mltable_schema_url': None, 'referenced_uris': None, 'type': 'uri_folder', 'is_anonymous': False, 'auto_increment_version': False, 'name': 'mini-tumors-images-scaled', 'description': 'Images 128x128 Scaled Outliers Removed', 'tags': {}, 'properties': {}, 'id': '/subscriptions/3bef7a06-fecc-47fc-ba25-a7899d62e16c/resourceGroups/Mini-Tumors-Germany/providers/Microsoft.MachineLearningServices/workspaces/Mini-Tumors-Workspace/data/mini-tumors-images-scaled/versions/5', 'Resource__source_path': None, 'base_path': '/Users/louis.heath/Documents/School/mini-tumors/notebooks', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x10cb92d00>, 'serialize': <msrest.serialization.Serializer object at 0x10979d9d0>, 'version': '5', 'latest_version': None, 'path': 'azureml://subscriptions/3bef7a06-fecc-47fc-ba25-a7899d62e16c/resourcegroups/Mini-Tumors-Germany/workspaces/Mini-Tumors-Workspace/datastores/workspaceblobstore/paths/LocalUpload/73f9826a213885fe962e833cc0ee47f1/converted/', 'datastore': None})\n",
      "\n",
      "Path to folder in Blob Storage:\n",
      "azureml://subscriptions/3bef7a06-fecc-47fc-ba25-a7899d62e16c/resourcegroups/Mini-Tumors-Germany/workspaces/Mini-Tumors-Workspace/datastores/workspaceblobstore/paths/LocalUpload/73f9826a213885fe962e833cc0ee47f1/converted/\n"
     ]
    }
   ],
   "source": [
    "# Uploading image files by creating a 'data asset URI FOLDER':\n",
    "\n",
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
    "from azure.ai.ml import Input\n",
    "\n",
    "my_data = Data(\n",
    "    path=\"../data/converted\",\n",
    "    type=AssetTypes.URI_FOLDER,\n",
    "    description=\"Images 128x128 Scaled Outliers Removed\",\n",
    "    name=\"mini-tumors-images-scaled\",\n",
    ")\n",
    "\n",
    "uri_folder_data_asset = ml_client.data.create_or_update(my_data)\n",
    "\n",
    "print(uri_folder_data_asset)\n",
    "print(\"\")\n",
    "print(\"Path to folder in Blob Storage:\")\n",
    "print(uri_folder_data_asset.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Convert the downloaded data to JSONL\n",
    "\n",
    "In this example, the fridge object dataset is annotated in the CSV file, where each image corresponds to a line. It defines a mapping of the filename to the labels. Since this is a multi-label classification problem, each image can be associated to multiple labels. In order to use this data to create an AzureML MLTable, we first need to convert it to the required JSONL format. Please refer to the [documentation on how to prepare datasets](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-prepare-datasets-for-automl-images).\n",
    "\n",
    "\n",
    "The following script is creating two .jsonl files (one for training and one for validation) in the corresponding MLTable folder. The train / validation ratio corresponds to 20% of the data going into the validation file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels.csv in correct format\n",
    "#filename,labels\n",
    "#1.jpg,carton\n",
    "#2.jpg,milk_bottle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "labels = np.load('../data/converted/images/labels.npy')\n",
    "\n",
    "new_labs = pd.DataFrame(columns=['filename','labels'])\n",
    "\n",
    "\n",
    "new_labs['filename'] = [ f'img{i}.png' for i in range(len(labels))]\n",
    "new_labs['labels'] = labels\n",
    "\n",
    "new_labs = new_labs.set_index('filename')\n",
    "\n",
    "new_labs.to_csv('../data/converted/images/labels.csv')\n",
    "new_labs.to_csv('../data/converted/labels.csv')\n",
    "#for i in len(labels):\n",
    "#    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remember to move to /images subforlder!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml://subscriptions/3bef7a06-fecc-47fc-ba25-a7899d62e16c/resourcegroups/Mini-Tumors-Germany/workspaces/Mini-Tumors-Workspace/datastores/workspaceblobstore/paths/LocalUpload/73f9826a213885fe962e833cc0ee47f1/converted/\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# In the big data folder\n",
    "src_images = \"../data/converted\"\n",
    "\n",
    "# We'll copy each JSONL file within its related MLTable folder\n",
    "# Do this locally in ./data for notebooks\n",
    "training_mltable_path = \"../data/training-mltable-folder/\"\n",
    "validation_mltable_path = \"../data/validation-mltable-folder/\"\n",
    "\n",
    "# Reasonable\n",
    "train_validation_ratio = 5\n",
    "\n",
    "# Path to the training and validation files\n",
    "train_annotations_file = os.path.join(training_mltable_path, \"train_annotations.jsonl\")\n",
    "validation_annotations_file = os.path.join(\n",
    "    validation_mltable_path, \"validation_annotations.jsonl\"\n",
    ")\n",
    "\n",
    "'''\n",
    "Lets not reinvent the wheel for now\n",
    "    \"image_details\":\n",
    "      {\n",
    "          \"format\": \"png\",\n",
    "          \"width\": \"128px\",\n",
    "          \"height\": \"1286px\"\n",
    "      },\n",
    "\n",
    "'''\n",
    "\n",
    "# Baseline of json line dictionary\n",
    "json_line_sample = {\n",
    "    \"image_url\": uri_folder_data_asset.path,\n",
    "    \"label\": [],\n",
    "}\n",
    "\n",
    "print(json_line_sample[\"image_url\"])\n",
    "\n",
    "\n",
    "labelFile = os.path.join(src_images, \"labels.csv\")\n",
    "\n",
    "# Read each annotation and convert it to jsonl line\n",
    "with open(train_annotations_file, \"w\") as train_f:\n",
    "    with open(validation_annotations_file, \"w\") as validation_f:\n",
    "        with open(labelFile, \"r\") as labels:\n",
    "            for i, line in enumerate(labels):\n",
    "                # Skipping the title line and any empty lines.\n",
    "                if i == 0 or len(line.strip()) == 0:\n",
    "                    continue\n",
    "                line_split = line.strip().split(\",\")\n",
    "                if len(line_split) != 2:\n",
    "                    print(\"Skipping the invalid line: {}\".format(line))\n",
    "                    continue\n",
    "                json_line = dict(json_line_sample)\n",
    "                json_line[\"image_url\"] += f\"images/{line_split[0]}\"\n",
    "                json_line[\"label\"] = line_split[1].strip().split(\" \")[0]\n",
    "\n",
    "                # Nothe the train validation split is not random\n",
    "                if i % train_validation_ratio == 0:\n",
    "                    # validation annotation\n",
    "                    validation_f.write(json.dumps(json_line) + \"\\n\")\n",
    "                else:\n",
    "                    # train annotation\n",
    "                    train_f.write(json.dumps(json_line) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Create MLTable data input\n",
    "\n",
    "Create MLTable data input using the jsonl files created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# WITH REMOTE PATH: If available already in the cloud/workspace-blob-store\\nmy_training_data_input = Input(type=AssetTypes.MLTABLE, path=\"azureml://datastores/workspaceblobstore/paths/vision-classification/train\")\\nmy_validation_data_input = Input(type=AssetTypes.MLTABLE, path=\"azureml://datastores/workspaceblobstore/paths/vision-classification/valid\")\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Training MLTable defined locally, with local data to be uploaded\n",
    "my_training_data_input = Input(type=AssetTypes.MLTABLE, path=training_mltable_path)\n",
    "\n",
    "# Validation MLTable defined locally, with local data to be uploaded\n",
    "my_validation_data_input = Input(type=AssetTypes.MLTABLE, path=validation_mltable_path)\n",
    "\n",
    "\n",
    "'''\n",
    "# WITH REMOTE PATH: If available already in the cloud/workspace-blob-store\n",
    "my_training_data_input = Input(type=AssetTypes.MLTABLE, path=\"azureml://datastores/workspaceblobstore/paths/vision-classification/train\")\n",
    "my_validation_data_input = Input(type=AssetTypes.MLTABLE, path=\"azureml://datastores/workspaceblobstore/paths/vision-classification/valid\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create data input from TabularDataset created using V1 sdk, specify the `type` as `AssetTypes.MLTABLE`, `mode` as `InputOutputModes.DIRECT` and `path` in the following format `azureml:<tabulardataset_name>:<version>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Training MLTable withv1 TabularDataset\\nmy_training_data_input = Input(\\n    type=AssetTypes.MLTABLE, path=\"azureml:multilabelFridgeObjectsTrainingDataset:1\",\\n    mode=InputOutputModes.DIRECT\\n)\\n\\n# Validation MLTable with v1 TabularDataset\\nmy_validation_data_input = Input(\\n    type=AssetTypes.MLTABLE, path=\"azureml:multilabelFridgeObjectsValidationDataset:1\",\\n    mode=InputOutputModes.DIRECT\\n)\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Training MLTable withv1 TabularDataset\n",
    "my_training_data_input = Input(\n",
    "    type=AssetTypes.MLTABLE, path=\"azureml:multilabelFridgeObjectsTrainingDataset:1\",\n",
    "    mode=InputOutputModes.DIRECT\n",
    ")\n",
    "\n",
    "# Validation MLTable with v1 TabularDataset\n",
    "my_validation_data_input = Input(\n",
    "    type=AssetTypes.MLTABLE, path=\"azureml:multilabelFridgeObjectsValidationDataset:1\",\n",
    "    mode=InputOutputModes.DIRECT\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Compute target setup\n",
    "\n",
    "You will need to provide a [Compute Target](https://docs.microsoft.com/en-us/azure/machine-learning/concept-azure-machine-learning-architecture#computes) that will be used for your AutoML model training. AutoML models for image tasks require [GPU SKUs](https://docs.microsoft.com/en-us/azure/virtual-machines/sizes-gpu) such as the ones from the NC, NCv2, NCv3, ND, NDv2 and NCasT4 series. We recommend using the NCsv3-series (with v100 GPUs) for faster training. Using a compute target with a multi-GPU VM SKU will leverage the multiple GPUs to speed up training. Additionally, setting up a compute target with multiple nodes will allow for faster model training by leveraging parallelism, when tuning hyperparameters for your model.\n",
    "\n",
    "\n",
    "Sizes :https://learn.microsoft.com/en-us/azure/machine-learning/concept-compute-target#supported-vm-series-and-sizes\n",
    "\n",
    "\n",
    "Regional availability and pricing: https://azure.microsoft.com/en-us/pricing/details/machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target.\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "from azure.core.exceptions import ResourceNotFoundError\n",
    "\n",
    "compute_name = \"gpu-cluster\"\n",
    "\n",
    "try:\n",
    "    _ = ml_client.compute.get(compute_name)\n",
    "    print(\"Found existing compute target.\")\n",
    "except ResourceNotFoundError:\n",
    "    print(\"Creating a new compute target...\")\n",
    "    compute_config = AmlCompute(\n",
    "        name=compute_name,\n",
    "        type=\"amlcompute\",\n",
    "        size=\"Standard_NC6\",\n",
    "        idle_time_before_scale_down=120,\n",
    "        min_instances=0,\n",
    "        max_instances=1,\n",
    "    )\n",
    "    begin_create_or_update.begin_create_or_update(compute_config).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Using default hyperparameter values for the specified algorithm\n",
    "Before doing a large sweep to search for the optimal models and hyperparameters, we recommend trying the default values for a given model to get a first baseline. Next, you can explore multiple hyperparameters for the same model before sweeping over multiple models and their parameters. This allows an iterative approach, as with multiple models and multiple hyperparameters for each (as we showcase in the next section), the search space grows exponentially, and  you need more iterations to find optimal configurations.\n",
    "\n",
    "Following functions are used to configure the AutoML image job:\n",
    "### image_classification() function parameters:\n",
    "The `image_classification()` factory function allows user to configure the training job.\n",
    "\n",
    "- `compute` - The compute on which the AutoML job will run. In this example we are using a compute called 'gpu-cluster' present in the workspace. You can replace it any other compute in the workspace.\n",
    "- `experiment_name` - The name of the experiment. An experiment is like a folder with multiple runs in Azure ML Workspace that should be related to the same logical machine learning experiment.\n",
    "- `name` - The name of the Job/Run. This is an optional property. If not specified, a random name will be generated.\n",
    "- `primary_metric` - The metric that AutoML will optimize for model selection.\n",
    "- `target_column_name` - The name of the column to target for predictions. It must always be specified. This parameter is applicable to 'training_data' and 'validation_data'.\n",
    "- `training_data` - The data to be used for training. It should contain both training feature columns and a target column. Optionally, this data can be split for segregating a validation or test dataset. \n",
    "You can use a registered MLTable in the workspace using the format '<mltable_name>:<version>' OR you can use a local file or folder as a MLTable. For e.g Input(mltable='my_mltable:1') OR Input(mltable=MLTable(local_path=\"./data\"))\n",
    "The parameter `training_data` must always be provided.\n",
    "\n",
    "\n",
    "### set_limits() function parameters:\n",
    "This is an optional configuration method to configure limits parameters such as timeouts.      \n",
    "    \n",
    "- `timeout_minutes` - Maximum amount of time in minutes that the whole AutoML job can take before the job terminates. If not specified, the default job's total timeout is 6 days (8,640 minutes).\n",
    "- `max_trials` - Parameter for maximum number of configurations to sweep. Must be an integer between 1 and 1000. When exploring just the default hyperparameters for a given model algorithm, set this parameter to 1. Default value is 1.\n",
    "- `max_concurrent_trials` - Maximum number of runs that can run concurrently. If not specified, all runs launch in parallel. If specified, must be an integer between 1 and 100.  Default value is 1.\n",
    "    NOTE: The number of concurrent runs is gated on the resources available in the specified compute target. Ensure that the compute target has the available resources for the desired concurrency.\n",
    "    \n",
    "### set_training_parameters() function parameters:\n",
    "This is an optional configuration method to configure fixed settings or parameters that don't change during the parameter space sweep. Some of the key parameters of this function are:\n",
    "\n",
    "- `model_name` - The name of the ML algorithm that we want to use in training job. Please refer to this [documentation](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-auto-train-image-models?tabs=CLI-v2#supported-model-algorithms) for supported model algorithm.\n",
    "- `number_of_epochs` - The number of training epochs. It must be positive integer (default value is 15).\n",
    "- `layers_to_freeze` - The number of layers to freeze in model for transfer learning. It must be a positive integer (default value is 0).\n",
    "- `early_stopping` - It enable early stopping logic during training, It must be boolean value (default is True).   \n",
    "- `optimizer` - Type of optimizer to use in training. It must be either sgd, adam, adamw (default is sgd).\n",
    "- `distributed` - It enable distributed training if compute target contain multiple GPUs. It must be boolean value (default is True).\n",
    "    \n",
    "If you wish to use the default hyperparameter values for a given algorithm (say `vitb16r224`), you can specify the job for your AutoML Image runs as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# general job parameters\n",
    "exp_name = \"Mini-Tumor-Classification-AML_V1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_classification_job = automl.image_classification(\n",
    "    compute=compute_name,\n",
    "    experiment_name=exp_name,\n",
    "    training_data=my_training_data_input,\n",
    "    validation_data=my_validation_data_input,\n",
    "    target_column_name=\"label\",\n",
    ")\n",
    "\n",
    "image_classification_job.set_limits(timeout_minutes=60)\n",
    "\n",
    "image_classification_job.set_training_parameters(model_name=\"seresnext\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submitting an AutoML job for Computer Vision tasks\n",
    "Once you've configured your job, you can submit it as a job in the workspace in order to train a vision model using your training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading training-mltable-folder (1.58 MBs): 100%|█| 1582376/1582376 [00:00<00:\n",
      "\n",
      "\n",
      "Uploading validation-mltable-folder (0.4 MBs): 100%|█| 395587/395587 [00:00<00:0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created job: ImageClassificationJob({'log_verbosity': <LogVerbosity.INFO: 'Info'>, 'target_column_name': 'label', 'validation_data_size': None, 'task_type': <TaskType.IMAGE_CLASSIFICATION: 'ImageClassification'>, 'training_data': {'type': 'mltable', 'path': 'azureml://datastores/workspaceblobstore/paths/LocalUpload/8510c5277a97e268ab28ae5e7675d1d3/training-mltable-folder'}, 'validation_data': {'type': 'mltable', 'path': 'azureml://datastores/workspaceblobstore/paths/LocalUpload/ef5ffaf8f7ab54efb70d3e073d3586f2/validation-mltable-folder'}, 'test_data': None, 'environment_id': None, 'environment_variables': None, 'outputs': {}, 'type': 'automl', 'status': 'NotStarted', 'log_files': None, 'name': 'boring_wheel_50pxv9bh28', 'description': None, 'tags': {}, 'properties': {'mlflow.source.git.repoURL': 'https://github.com/gakhromov/mini-tumors', 'mlflow.source.git.branch': 'azure_ml', 'mlflow.source.git.commit': '52033550558d310109afedfc4295b10eebf650fa', 'azureml.git.dirty': 'True'}, 'id': '/subscriptions/3bef7a06-fecc-47fc-ba25-a7899d62e16c/resourceGroups/Mini-Tumors-Germany/providers/Microsoft.MachineLearningServices/workspaces/Mini-Tumors-Workspace/jobs/boring_wheel_50pxv9bh28', 'Resource__source_path': None, 'base_path': '/Users/louis.heath/Documents/School/mini-tumors/notebooks', 'creation_context': <azure.ai.ml._restclient.v2022_10_01_preview.models._models_py3.SystemData object at 0x12757c730>, 'serialize': <msrest.serialization.Serializer object at 0x12750eb50>, 'inputs': {}, 'display_name': 'boring_wheel_50pxv9bh28', 'experiment_name': 'Mini-Tumor-Classification-AML_V1', 'compute': 'gpu-cluster', 'services': {'Tracking': <azure.ai.ml._restclient.v2022_10_01_preview.models._models_py3.JobService object at 0x12757c940>, 'Studio': <azure.ai.ml._restclient.v2022_10_01_preview.models._models_py3.JobService object at 0x12757c2b0>}, 'resources': <azure.ai.ml._restclient.v2022_10_01_preview.models._models_py3.JobResourceConfiguration object at 0x12757c700>, 'identity': None, 'limits': <azure.ai.ml.entities._job.automl.image.image_limit_settings.ImageLimitSettings object at 0x10d42dc40>, 'sweep': None, 'training_parameters': <azure.ai.ml.entities._job.automl.image.image_model_settings.ImageModelSettingsClassification object at 0x12772caf0>, 'search_space': None, 'primary_metric': <ClassificationPrimaryMetrics.ACCURACY: 'Accuracy'>})\n"
     ]
    }
   ],
   "source": [
    "#Submit the AutoML job\n",
    "returned_job = ml_client.jobs.create_or_update(image_classification_job)\n",
    "\n",
    "print(f\"Created job: {returned_job}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: boring_wheel_50pxv9bh28\n",
      "Web View: https://ml.azure.com/runs/boring_wheel_50pxv9bh28?wsid=/subscriptions/3bef7a06-fecc-47fc-ba25-a7899d62e16c/resourcegroups/Mini-Tumors-Germany/workspaces/Mini-Tumors-Workspace\n"
     ]
    }
   ],
   "source": [
    "ml_client.jobs.stream(returned_job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Hyperparameter sweeping for your AutoML models for computer vision tasks\n",
    "\n",
    "When using AutoML for Images, you can perform a hyperparameter sweep over a defined parameter space to find the optimal model. In this example, we sweep over the hyperparameters for `vitb16r224` and `seresnext` models, choosing from a range of values for learning_rate, gradient_accumulation_step, validation_resize_size, etc., to generate a model with the optimal 'iou'. If hyperparameter values are not specified, then default values are used for the specified algorithm.\n",
    "\n",
    "set_sweep function is used to configure the sweep settings:\n",
    "### set_sweep() parameters:\n",
    "\n",
    "- `sampling_algorithm` - Sampling method to use for sweeping over the defined parameter space. Please refer to this [documentation](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-auto-train-image-models?tabs=SDK-v2#sampling-methods-for-the-sweep) for list of supported sampling methods.\n",
    "- `early_termination` - Early termination policy to end poorly performing runs. If no termination policy is specified, all configurations are run to completion. Please refer to this [documentation](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-auto-train-image-models?tabs=SDK-v2#early-termination-policies) for supported early termination policies.\n",
    "\n",
    "We use Random Sampling to pick samples from this parameter space and try a total of 10 iterations with these different samples, running 2 iterations at a time on our compute target. Please note that the more parameters the space has, the more iterations you need to find optimal models.\n",
    "\n",
    "We leverage the Bandit early termination policy which will terminate poor performing configs (those that are not within 20% slack of the best performing config), thus significantly saving compute resources.\n",
    "\n",
    "For more details on model and hyperparameter sweeping, please refer to the [documentation](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_classification_job = automl.image_classification(\n",
    "    compute=compute_name,\n",
    "    experiment_name=exp_name,\n",
    "    training_data=my_training_data_input,\n",
    "    validation_data=my_validation_data_input,\n",
    "    target_column_name=\"label\",\n",
    "    primary_metric=ClassificationPrimaryMetrics.ACCURACY,\n",
    ")\n",
    "\n",
    "# TODO: Perhaps try accuracy for primary metric?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Perhaps try accuracy?\n",
    "#ClassificationPrimaryMetrics.AUC_WEIGHTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_classification_job.set_limits(\n",
    "    timeout_minutes=1440, #12 hours\n",
    "    max_trials=20,\n",
    "    max_concurrent_trials=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_transformers =   SearchSpace(\n",
    "              model_name=\"vitb16r224\",\n",
    "              # According to: https://learn.microsoft.com/en-us/azure/machine-learning/reference-automl-images-hyperparameters\n",
    "              layers_to_freeze=Choice([0, 5, 9]),\n",
    "              # 0 for no weighted loss, 1 for weighted loss with sqrt.(class_weights), 2 for weighted loss with class_weights.\n",
    "              weighted_loss=Choice([0,2]),\n",
    "              learning_rate=Choice([0.0001, 0.01, 0.01]),\n",
    "              number_of_epochs=30,\n",
    "              optimizer=\"sgd\",\n",
    "        )\n",
    "\n",
    "ss_cnn = SearchSpace(\n",
    "          model_name=Choice([\"seresnext\", \"resnet50\", \"resnet152\"]),\n",
    "          # According to: https://learn.microsoft.com/en-us/azure/machine-learning/reference-automl-images-hyperparameters\n",
    "          layers_to_freeze=Choice([0, 2]),\n",
    "          # 0 for no weighted loss, 1 for weighted loss with sqrt.(class_weights), 2 for weighted loss with class_weights.\n",
    "          weighted_loss=Choice([0,2]),\n",
    "          learning_rate=Choice([0.0001, 0.001, 0.01]),\n",
    "          optimizer= Choice([\"sgd\",\"adamw\"]),\n",
    "          number_of_epochs=30\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_classification_job.extend_search_space([ss_cnn, ss_transformers]) # ss_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.sweep import MedianStoppingPolicy\n",
    "\n",
    "image_classification_job.set_sweep(\n",
    "    sampling_algorithm=\"Random\",\n",
    "    early_termination= MedianStoppingPolicy(delay_evaluation = 15, evaluation_interval = 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created job: ImageClassificationJob({'log_verbosity': <LogVerbosity.INFO: 'Info'>, 'target_column_name': 'label', 'validation_data_size': None, 'task_type': <TaskType.IMAGE_CLASSIFICATION: 'ImageClassification'>, 'training_data': {'type': 'mltable', 'path': 'azureml://datastores/workspaceblobstore/paths/LocalUpload/8510c5277a97e268ab28ae5e7675d1d3/training-mltable-folder'}, 'validation_data': {'type': 'mltable', 'path': 'azureml://datastores/workspaceblobstore/paths/LocalUpload/ef5ffaf8f7ab54efb70d3e073d3586f2/validation-mltable-folder'}, 'test_data': None, 'environment_id': None, 'environment_variables': None, 'outputs': {}, 'type': 'automl', 'status': 'NotStarted', 'log_files': None, 'name': 'jovial_fork_74gkzcrl8c', 'description': None, 'tags': {}, 'properties': {'mlflow.source.git.repoURL': 'https://github.com/gakhromov/mini-tumors', 'mlflow.source.git.branch': 'azure_ml', 'mlflow.source.git.commit': '52033550558d310109afedfc4295b10eebf650fa', 'azureml.git.dirty': 'True'}, 'id': '/subscriptions/3bef7a06-fecc-47fc-ba25-a7899d62e16c/resourceGroups/Mini-Tumors-Germany/providers/Microsoft.MachineLearningServices/workspaces/Mini-Tumors-Workspace/jobs/jovial_fork_74gkzcrl8c', 'Resource__source_path': None, 'base_path': '/Users/louis.heath/Documents/School/mini-tumors/notebooks', 'creation_context': <azure.ai.ml._restclient.v2022_10_01_preview.models._models_py3.SystemData object at 0x142fb84c0>, 'serialize': <msrest.serialization.Serializer object at 0x142fb8fd0>, 'inputs': {}, 'display_name': 'jovial_fork_74gkzcrl8c', 'experiment_name': 'Mini-Tumor-Classification-AML_V1', 'compute': 'gpu-cluster', 'services': {'Tracking': <azure.ai.ml._restclient.v2022_10_01_preview.models._models_py3.JobService object at 0x142fb8460>, 'Studio': <azure.ai.ml._restclient.v2022_10_01_preview.models._models_py3.JobService object at 0x142fb84f0>}, 'resources': <azure.ai.ml._restclient.v2022_10_01_preview.models._models_py3.JobResourceConfiguration object at 0x142fb83d0>, 'identity': None, 'limits': <azure.ai.ml.entities._job.automl.image.image_limit_settings.ImageLimitSettings object at 0x143013eb0>, 'sweep': <azure.ai.ml.entities._job.automl.image.image_sweep_settings.ImageSweepSettings object at 0x10d42da60>, 'training_parameters': None, 'search_space': [<azure.ai.ml.entities._job.automl.image.image_classification_search_space.ImageClassificationSearchSpace object at 0x142fb8940>, <azure.ai.ml.entities._job.automl.image.image_classification_search_space.ImageClassificationSearchSpace object at 0x142fb8e80>, <azure.ai.ml.entities._job.automl.image.image_classification_search_space.ImageClassificationSearchSpace object at 0x142fb8ee0>, <azure.ai.ml.entities._job.automl.image.image_classification_search_space.ImageClassificationSearchSpace object at 0x142fb87f0>], 'primary_metric': <ClassificationPrimaryMetrics.ACCURACY: 'Accuracy'>})\n"
     ]
    }
   ],
   "source": [
    "# Submit the AutoML job\n",
    "returned_job = ml_client.jobs.create_or_update(\n",
    "    image_classification_job\n",
    ")  # submit the job to the backend\n",
    "\n",
    "print(f\"Created job: {returned_job}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: jovial_fork_74gkzcrl8c\n",
      "Web View: https://ml.azure.com/runs/jovial_fork_74gkzcrl8c?wsid=/subscriptions/3bef7a06-fecc-47fc-ba25-a7899d62e16c/resourcegroups/Mini-Tumors-Germany/workspaces/Mini-Tumors-Workspace\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying due to transient client side error HTTPSConnectionPool(host='westus2-0.in.applicationinsights.azure.com', port=443): Max retries exceeded with url: /v2.1/track (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x143062d60>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')).\n",
      "Retrying due to transient client side error HTTPSConnectionPool(host='westus2-0.in.applicationinsights.azure.com', port=443): Max retries exceeded with url: /v2.1/track (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x14307b820>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')).\n",
      "Retrying due to transient client side error HTTPSConnectionPool(host='westus2-0.in.applicationinsights.azure.com', port=443): Max retries exceeded with url: /v2.1/track (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x14307b6a0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')).\n",
      "Retrying due to transient client side error HTTPSConnectionPool(host='westus2-0.in.applicationinsights.azure.com', port=443): Max retries exceeded with url: /v2.1/track (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x14307bfd0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')).\n",
      "Retrying due to transient client side error HTTPSConnectionPool(host='westus2-0.in.applicationinsights.azure.com', port=443): Max retries exceeded with url: /v2.1/track (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x14307bee0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')).\n",
      "Retrying due to transient client side error HTTPSConnectionPool(host='westus2-0.in.applicationinsights.azure.com', port=443): Max retries exceeded with url: /v2.1/track (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x14307b400>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')).\n"
     ]
    },
    {
     "ename": "ClientAuthenticationError",
     "evalue": "ERROR: The command failed with an unexpected error. Here is the traceback:\nERROR: HTTPSConnectionPool(host='login.microsoftonline.com', port=443): Max retries exceeded with url: /16bf80d2-3fa8-456d-8ca3-59cab29a2b99/oauth2/v2.0/token (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x107270fd0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\nTraceback (most recent call last):\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/urllib3/connection.py\", line 174, in _new_conn\n    conn = connection.create_connection(\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/urllib3/util/connection.py\", line 73, in create_connection\n    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n  File \"/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/socket.py\", line 955, in getaddrinfo\n    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\nsocket.gaierror: [Errno 8] nodename nor servname provided, or not known\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 699, in urlopen\n    httplib_response = self._make_request(\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 382, in _make_request\n    self._validate_conn(conn)\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 1010, in _validate_conn\n    conn.connect()\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/urllib3/connection.py\", line 358, in connect\n    conn = self._new_conn()\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/urllib3/connection.py\", line 186, in _new_conn\n    raise NewConnectionError(\nurllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x107270fd0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/requests/adapters.py\", line 439, in send\n    resp = conn.urlopen(\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n    return self.urlopen(\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 755, in urlopen\n    retries = retries.increment(\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/urllib3/util/retry.py\", line 574, in increment\n    raise MaxRetryError(_pool, url, error or ResponseError(cause))\nurllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='login.microsoftonline.com', port=443): Max retries exceeded with url: /16bf80d2-3fa8-456d-8ca3-59cab29a2b99/oauth2/v2.0/token (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x107270fd0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/knack/cli.py\", line 233, in invoke\n    cmd_result = self.invocation.execute(args)\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/azure/cli/core/commands/__init__.py\", line 663, in execute\n    raise ex\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/azure/cli/core/commands/__init__.py\", line 726, in _run_jobs_serially\n    results.append(self._run_job(expanded_arg, cmd_copy))\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/azure/cli/core/commands/__init__.py\", line 697, in _run_job\n    result = cmd_copy(params)\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/azure/cli/core/commands/__init__.py\", line 333, in __call__\n    return self.handler(*args, **kwargs)\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/azure/cli/core/commands/command_operation.py\", line 121, in handler\n    return op(**command_args)\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/azure/cli/command_modules/profile/custom.py\", line 66, in get_access_token\n    creds, subscription, tenant = profile.get_raw_token(subscription=subscription, resource=resource, scopes=scopes,\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/azure/cli/core/_profile.py\", line 383, in get_raw_token\n    sdk_token = credential.get_token(*scopes)\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/azure/cli/core/auth/msal_authentication.py\", line 63, in get_token\n    result = self.acquire_token_silent_with_error(list(scopes), self._account, claims_challenge=claims, **kwargs)\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/msal/application.py\", line 1287, in acquire_token_silent_with_error\n    result = self._acquire_token_silent_from_cache_and_possibly_refresh_it(\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/msal/application.py\", line 1392, in _acquire_token_silent_from_cache_and_possibly_refresh_it\n    result = _clean_up(self._acquire_token_silent_by_finding_rt_belongs_to_me_or_my_family(\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/msal/application.py\", line 1444, in _acquire_token_silent_by_finding_rt_belongs_to_me_or_my_family\n    last_resp = at = self._acquire_token_silent_by_finding_specific_refresh_token(\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/msal/application.py\", line 1491, in _acquire_token_silent_by_finding_specific_refresh_token\n    response = client.obtain_token_by_refresh_token(\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/msal/oauth2cli/oauth2.py\", line 830, in obtain_token_by_refresh_token\n    resp = super(Client, self).obtain_token_by_refresh_token(\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/msal/oauth2cli/oauth2.py\", line 262, in obtain_token_by_refresh_token\n    return self._obtain_token(\"refresh_token\", data=data, **kwargs)\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/msal/oauth2cli/oidc.py\", line 116, in _obtain_token\n    ret = super(Client, self)._obtain_token(grant_type, *args, **kwargs)\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/msal/oauth2cli/oauth2.py\", line 771, in _obtain_token\n    resp = super(Client, self)._obtain_token(\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/msal/oauth2cli/oauth2.py\", line 234, in _obtain_token\n    resp = (post or self._http_client.post)(\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/msal/individual_cache.py\", line 269, in wrapper\n    value = function(*args, **kwargs)\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/msal/individual_cache.py\", line 269, in wrapper\n    value = function(*args, **kwargs)\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/requests/sessions.py\", line 590, in post\n    return self.request('POST', url, data=data, json=json, **kwargs)\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/requests/sessions.py\", line 542, in request\n    resp = self.send(prep, **send_kwargs)\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/requests/sessions.py\", line 655, in send\n    r = adapter.send(request, **kwargs)\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/requests/adapters.py\", line 516, in send\n    raise ConnectionError(e, request=request)\nrequests.exceptions.ConnectionError: HTTPSConnectionPool(host='login.microsoftonline.com', port=443): Max retries exceeded with url: /16bf80d2-3fa8-456d-8ca3-59cab29a2b99/oauth2/v2.0/token (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x107270fd0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\nTo check existing issues, please visit: https://github.com/Azure/azure-cli/issues\nTo open a new issue, please run `az feedback`\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/azure/identity/_credentials/azure_cli.py:148\u001b[0m, in \u001b[0;36m_run_command\u001b[0;34m(command)\u001b[0m\n\u001b[1;32m    146\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m--> 148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;66;03m# non-zero return from shell\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/subprocess.py:424\u001b[0m, in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    422\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m empty\n\u001b[0;32m--> 424\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m           \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstdout\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/subprocess.py:528\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[0;32m--> 528\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[38;5;241m.\u001b[39margs,\n\u001b[1;32m    529\u001b[0m                                  output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process\u001b[38;5;241m.\u001b[39margs, retcode, stdout, stderr)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['/bin/sh', '-c', 'az account get-access-token --output json --resource https://management.azure.com']' returned non-zero exit status 1.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mClientAuthenticationError\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [105], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mml_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjobs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreturned_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/azure/core/tracing/decorator.py:78\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/azure/ai/ml/_telemetry/activity.py:259\u001b[0m, in \u001b[0;36mmonitor_with_activity.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m log_activity(logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, custom_dimensions):\n\u001b[0;32m--> 259\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/azure/ai/ml/operations/_job_operations.py:617\u001b[0m, in \u001b[0;36mJobOperations.stream\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_pipeline_child_job(job_object):\n\u001b[1;32m    615\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PipelineChildJobError(job_id\u001b[38;5;241m=\u001b[39mjob_object\u001b[38;5;241m.\u001b[39mid)\n\u001b[0;32m--> 617\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream_logs_until_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_runs_operations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_object\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_datastore_operations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequests_pipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_requests_pipeline\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/azure/ai/ml/operations/_job_ops_helper.py:236\u001b[0m, in \u001b[0;36mstream_logs_until_completion\u001b[0;34m(run_operations, job_resource, datastore_operations, raise_exception_on_failed_job, requests_pipeline)\u001b[0m\n\u001b[1;32m    234\u001b[0m file_handle\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m    235\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(_wait_before_polling(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m poll_start_time))\n\u001b[0;32m--> 236\u001b[0m _current_details: RunDetails \u001b[38;5;241m=\u001b[39m \u001b[43mrun_operations\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_run_details\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_name\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# TODO use FileWatcher\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m job_type\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m JobType\u001b[38;5;241m.\u001b[39mPIPELINE:\n\u001b[1;32m    238\u001b[0m     legacy_folder_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/logs/azureml/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/azure/ai/ml/operations/_run_operations.py:40\u001b[0m, in \u001b[0;36mRunOperations.get_run_details\u001b[0;34m(self, run_id)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_run_details\u001b[39m(\u001b[38;5;28mself\u001b[39m, run_id: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RunDetails:\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_operation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_details\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_operation_scope\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubscription_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_operation_scope\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresource_group_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_workspace_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/azure/core/tracing/decorator.py:78\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/azure/ai/ml/_restclient/runhistory/operations/_runs_operations.py:1873\u001b[0m, in \u001b[0;36mRunsOperations.get_details\u001b[0;34m(self, subscription_id, resource_group_name, workspace_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m   1870\u001b[0m request \u001b[38;5;241m=\u001b[39m _convert_request(request)\n\u001b[1;32m   1871\u001b[0m request\u001b[38;5;241m.\u001b[39murl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mformat_url(request\u001b[38;5;241m.\u001b[39murl)\n\u001b[0;32m-> 1873\u001b[0m pipeline_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m   1874\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1875\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1876\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   1877\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1878\u001b[0m response \u001b[38;5;241m=\u001b[39m pipeline_response\u001b[38;5;241m.\u001b[39mhttp_response\n\u001b[1;32m   1880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m200\u001b[39m]:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/azure/core/pipeline/_base.py:211\u001b[0m, in \u001b[0;36mPipeline.run\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m pipeline_request \u001b[38;5;241m=\u001b[39m PipelineRequest(\n\u001b[1;32m    204\u001b[0m     request, context\n\u001b[1;32m    205\u001b[0m )  \u001b[38;5;66;03m# type: PipelineRequest[HTTPRequestType]\u001b[39;00m\n\u001b[1;32m    206\u001b[0m first_node \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl_policies[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl_policies\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m _TransportRunner(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport)\n\u001b[1;32m    210\u001b[0m )\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfirst_node\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline_request\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/azure/core/pipeline/_base.py:71\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     69\u001b[0m _await_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy\u001b[38;5;241m.\u001b[39mon_request, request)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 71\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     _await_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy\u001b[38;5;241m.\u001b[39mon_exception, request)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/azure/core/pipeline/_base.py:71\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     69\u001b[0m _await_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy\u001b[38;5;241m.\u001b[39mon_request, request)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 71\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     _await_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy\u001b[38;5;241m.\u001b[39mon_exception, request)\n",
      "    \u001b[0;31m[... skipping similar frames: _SansIOHTTPPolicyRunner.send at line 71 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/azure/core/pipeline/_base.py:71\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     69\u001b[0m _await_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy\u001b[38;5;241m.\u001b[39mon_request, request)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 71\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     _await_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy\u001b[38;5;241m.\u001b[39mon_exception, request)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/azure/mgmt/core/policies/_base.py:47\u001b[0m, in \u001b[0;36mARMAutoResourceProviderRegistrationPolicy.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend\u001b[39m(\u001b[38;5;28mself\u001b[39m, request):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m# type: (PipelineRequest[HTTPRequestType], Any) -> PipelineResponse[HTTPRequestType, HTTPResponseType]\u001b[39;00m\n\u001b[1;32m     46\u001b[0m     http_request \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mhttp_request\n\u001b[0;32m---> 47\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mhttp_response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m409\u001b[39m:\n\u001b[1;32m     49\u001b[0m         rp_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_rp_not_registered_err(response)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/azure/core/pipeline/policies/_redirect.py:153\u001b[0m, in \u001b[0;36mRedirectPolicy.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    151\u001b[0m redirect_settings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfigure_redirects(request\u001b[38;5;241m.\u001b[39mcontext\u001b[38;5;241m.\u001b[39moptions)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m retryable:\n\u001b[0;32m--> 153\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m     redirect_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_redirect_location(response)\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m redirect_location \u001b[38;5;129;01mand\u001b[39;00m redirect_settings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallow\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/azure/core/pipeline/policies/_retry.py:445\u001b[0m, in \u001b[0;36mRetryPolicy.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    443\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_timeout(request, absolute_timeout, is_response_error)\n\u001b[0;32m--> 445\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_retry(retry_settings, response):\n\u001b[1;32m    447\u001b[0m     retry_active \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mincrement(retry_settings, response\u001b[38;5;241m=\u001b[39mresponse)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/azure/core/pipeline/policies/_authentication.py:111\u001b[0m, in \u001b[0;36mBearerTokenCredentialPolicy.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend\u001b[39m(\u001b[38;5;28mself\u001b[39m, request):\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;66;03m# type: (PipelineRequest) -> PipelineResponse\u001b[39;00m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;124;03m\"\"\"Authorize request with a bearer token and send it to the next policy\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m    :param request: The pipeline request object\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m    :type request: ~azure.core.pipeline.PipelineRequest\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    113\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext\u001b[38;5;241m.\u001b[39msend(request)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/azure/core/pipeline/policies/_authentication.py:88\u001b[0m, in \u001b[0;36mBearerTokenCredentialPolicy.on_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enforce_https(request)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_need_new_token:\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_credential\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_token\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_scopes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_headers(request\u001b[38;5;241m.\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39mheaders, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_token\u001b[38;5;241m.\u001b[39mtoken)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/azure/identity/_internal/decorators.py:32\u001b[0m, in \u001b[0;36mlog_get_token.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 32\u001b[0m         token \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m         _LOGGER\u001b[38;5;241m.\u001b[39mlog(\n\u001b[1;32m     34\u001b[0m             logging\u001b[38;5;241m.\u001b[39mDEBUG \u001b[38;5;28;01mif\u001b[39;00m within_credential_chain\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;28;01melse\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mINFO, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m succeeded\u001b[39m\u001b[38;5;124m\"\u001b[39m, qualified_name\n\u001b[1;32m     35\u001b[0m         )\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _LOGGER\u001b[38;5;241m.\u001b[39misEnabledFor(logging\u001b[38;5;241m.\u001b[39mDEBUG):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/azure/identity/_credentials/azure_cli.py:80\u001b[0m, in \u001b[0;36mAzureCliCredential.get_token\u001b[0;34m(self, *scopes, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tenant:\n\u001b[1;32m     79\u001b[0m     command \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m --tenant \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m tenant\n\u001b[0;32m---> 80\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43m_run_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m token \u001b[38;5;241m=\u001b[39m parse_token(output)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m token:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/azure/identity/_credentials/azure_cli.py:161\u001b[0m, in \u001b[0;36m_run_command\u001b[0;34m(command)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    160\u001b[0m         message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to invoke Azure CLI\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 161\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ClientAuthenticationError(message\u001b[38;5;241m=\u001b[39mmessage)\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# failed to execute 'cmd' or '/bin/sh'; CLI may or may not be installed\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     error \u001b[38;5;241m=\u001b[39m CredentialUnavailableError(message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to execute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(args[\u001b[38;5;241m0\u001b[39m]))\n",
      "\u001b[0;31mClientAuthenticationError\u001b[0m: ERROR: The command failed with an unexpected error. Here is the traceback:\nERROR: HTTPSConnectionPool(host='login.microsoftonline.com', port=443): Max retries exceeded with url: /16bf80d2-3fa8-456d-8ca3-59cab29a2b99/oauth2/v2.0/token (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x107270fd0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\nTraceback (most recent call last):\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/urllib3/connection.py\", line 174, in _new_conn\n    conn = connection.create_connection(\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/urllib3/util/connection.py\", line 73, in create_connection\n    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n  File \"/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/socket.py\", line 955, in getaddrinfo\n    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\nsocket.gaierror: [Errno 8] nodename nor servname provided, or not known\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 699, in urlopen\n    httplib_response = self._make_request(\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 382, in _make_request\n    self._validate_conn(conn)\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 1010, in _validate_conn\n    conn.connect()\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/urllib3/connection.py\", line 358, in connect\n    conn = self._new_conn()\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/urllib3/connection.py\", line 186, in _new_conn\n    raise NewConnectionError(\nurllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x107270fd0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/requests/adapters.py\", line 439, in send\n    resp = conn.urlopen(\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n    return self.urlopen(\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 755, in urlopen\n    retries = retries.increment(\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/urllib3/util/retry.py\", line 574, in increment\n    raise MaxRetryError(_pool, url, error or ResponseError(cause))\nurllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='login.microsoftonline.com', port=443): Max retries exceeded with url: /16bf80d2-3fa8-456d-8ca3-59cab29a2b99/oauth2/v2.0/token (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x107270fd0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/knack/cli.py\", line 233, in invoke\n    cmd_result = self.invocation.execute(args)\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/azure/cli/core/commands/__init__.py\", line 663, in execute\n    raise ex\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/azure/cli/core/commands/__init__.py\", line 726, in _run_jobs_serially\n    results.append(self._run_job(expanded_arg, cmd_copy))\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/azure/cli/core/commands/__init__.py\", line 697, in _run_job\n    result = cmd_copy(params)\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/azure/cli/core/commands/__init__.py\", line 333, in __call__\n    return self.handler(*args, **kwargs)\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/azure/cli/core/commands/command_operation.py\", line 121, in handler\n    return op(**command_args)\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/azure/cli/command_modules/profile/custom.py\", line 66, in get_access_token\n    creds, subscription, tenant = profile.get_raw_token(subscription=subscription, resource=resource, scopes=scopes,\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/azure/cli/core/_profile.py\", line 383, in get_raw_token\n    sdk_token = credential.get_token(*scopes)\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/azure/cli/core/auth/msal_authentication.py\", line 63, in get_token\n    result = self.acquire_token_silent_with_error(list(scopes), self._account, claims_challenge=claims, **kwargs)\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/msal/application.py\", line 1287, in acquire_token_silent_with_error\n    result = self._acquire_token_silent_from_cache_and_possibly_refresh_it(\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/msal/application.py\", line 1392, in _acquire_token_silent_from_cache_and_possibly_refresh_it\n    result = _clean_up(self._acquire_token_silent_by_finding_rt_belongs_to_me_or_my_family(\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/msal/application.py\", line 1444, in _acquire_token_silent_by_finding_rt_belongs_to_me_or_my_family\n    last_resp = at = self._acquire_token_silent_by_finding_specific_refresh_token(\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/msal/application.py\", line 1491, in _acquire_token_silent_by_finding_specific_refresh_token\n    response = client.obtain_token_by_refresh_token(\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/msal/oauth2cli/oauth2.py\", line 830, in obtain_token_by_refresh_token\n    resp = super(Client, self).obtain_token_by_refresh_token(\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/msal/oauth2cli/oauth2.py\", line 262, in obtain_token_by_refresh_token\n    return self._obtain_token(\"refresh_token\", data=data, **kwargs)\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/msal/oauth2cli/oidc.py\", line 116, in _obtain_token\n    ret = super(Client, self)._obtain_token(grant_type, *args, **kwargs)\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/msal/oauth2cli/oauth2.py\", line 771, in _obtain_token\n    resp = super(Client, self)._obtain_token(\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/msal/oauth2cli/oauth2.py\", line 234, in _obtain_token\n    resp = (post or self._http_client.post)(\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/msal/individual_cache.py\", line 269, in wrapper\n    value = function(*args, **kwargs)\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/msal/individual_cache.py\", line 269, in wrapper\n    value = function(*args, **kwargs)\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/requests/sessions.py\", line 590, in post\n    return self.request('POST', url, data=data, json=json, **kwargs)\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/requests/sessions.py\", line 542, in request\n    resp = self.send(prep, **send_kwargs)\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/requests/sessions.py\", line 655, in send\n    r = adapter.send(request, **kwargs)\n  File \"/opt/homebrew/Cellar/azure-cli/2.42.0/libexec/lib/python3.10/site-packages/requests/adapters.py\", line 516, in send\n    raise ConnectionError(e, request=request)\nrequests.exceptions.ConnectionError: HTTPSConnectionPool(host='login.microsoftonline.com', port=443): Max retries exceeded with url: /16bf80d2-3fa8-456d-8ca3-59cab29a2b99/oauth2/v2.0/token (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x107270fd0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\nTo check existing issues, please visit: https://github.com/Azure/azure-cli/issues\nTo open a new issue, please run `az feedback`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying due to transient client side error HTTPSConnectionPool(host='westus2-0.in.applicationinsights.azure.com', port=443): Max retries exceeded with url: /v2.1/track (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x14307bac0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')).\n",
      "Retrying due to transient client side error HTTPSConnectionPool(host='westus2-0.in.applicationinsights.azure.com', port=443): Max retries exceeded with url: /v2.1/track (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x143062a60>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')).\n",
      "Path /var/folders/1r/s3cngdnd4qn_4zjl5q1dk6200000gq/T/opencensus-python-71b954a8-6b7d-43f5-986c-3d3a6605d803/2022-11-18T221618.576910-d4bf776d.blob.tmp does not exist or is inaccessible.\n"
     ]
    }
   ],
   "source": [
    "ml_client.jobs.stream(returned_job.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>Mini-Tumor-Classification-AML_V1</td><td>busy_sun_x51p25t921_HD</td><td>sweep</td><td>Running</td><td><a href=\"https://ml.azure.com/runs/busy_sun_x51p25t921_HD?wsid=/subscriptions/3bef7a06-fecc-47fc-ba25-a7899d62e16c/resourcegroups/Mini-Tumors-Germany/workspaces/Mini-Tumors-Workspace&amp;tid=16bf80d2-3fa8-456d-8ca3-59cab29a2b99\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
      ],
      "text/plain": [
       "SweepJob({'type': 'sweep', 'status': 'Running', 'log_files': None, 'name': 'busy_sun_x51p25t921_HD', 'description': None, 'tags': {'_aml_system_azureml.automlComponent': 'AutoML', '_aml_system_max_concurrent_jobs': '1', 'max_concurrent_jobs': '1', '_aml_system_max_total_jobs': '20', 'max_total_jobs': '20', '_aml_system_max_duration_minutes': '720', 'max_duration_minutes': '720', '_aml_system_policy_config': '{\"name\":\"MedianStopping\",\"properties\":{\"evaluation_interval\":2,\"delay_evaluation\":5}}', 'policy_config': '{\"name\":\"MedianStopping\",\"properties\":{\"evaluation_interval\":2,\"delay_evaluation\":5}}', '_aml_system_generator_config': '{\"name\":\"RANDOM\",\"parameter_space\":{\"model\":[\"choice\",[[{\"weighted_loss\":[\"choice\",[[0,2]]],\"early_stopping\":\"True\",\"layers_to_freeze\":[\"choice\",[[0,2]]],\"learning_rate\":[\"choice\",[[0.0001,0.001,0.01]]],\"model_name\":[\"choice\",[[\"seresnext\",\"resnet50\",\"resnet152\"]]],\"number_of_epochs\":20,\"optimizer\":[\"choice\",[[\"sgd\",\"adamw\"]]]},{\"weighted_loss\":[\"choice\",[[0,2]]],\"layers_to_freeze\":[\"choice\",[[0,5,9]]],\"learning_rate\":[\"choice\",[[0.0001,0.01]]],\"model_name\":\"vitb16r224\",\"number_of_epochs\":20,\"optimizer\":\"sgd\"}]]]},\"properties\":null}', 'generator_config': '{\"name\":\"RANDOM\",\"parameter_space\":{\"model\":[\"choice\",[[{\"weighted_loss\":[\"choice\",[[0,2]]],\"early_stopping\":\"True\",\"layers_to_freeze\":[\"choice\",[[0,2]]],\"learning_rate\":[\"choice\",[[0.0001,0.001,0.01]]],\"model_name\":[\"choice\",[[\"seresnext\",\"resnet50\",\"resnet152\"]]],\"number_of_epochs\":20,\"optimizer\":[\"choice\",[[\"sgd\",\"adamw\"]]]},{\"weighted_loss\":[\"choice\",[[0,2]]],\"layers_to_freeze\":[\"choice\",[[0,5,9]]],\"learning_rate\":[\"choice\",[[0.0001,0.01]]],\"model_name\":\"vitb16r224\",\"number_of_epochs\":20,\"optimizer\":\"sgd\"}]]]},\"properties\":null}', '_aml_system_primary_metric_config': '{\"name\":\"accuracy\",\"goal\":\"maximize\"}', 'primary_metric_config': '{\"name\":\"accuracy\",\"goal\":\"maximize\"}', '_aml_system_platform_config': '{\"ServiceAddress\":\"https://westeurope.api.azureml.ms\",\"SubscriptionId\":\"3bef7a06-fecc-47fc-ba25-a7899d62e16c\",\"ResourceGroupName\":\"Mini-Tumors-Germany\",\"WorkspaceName\":\"Mini-Tumors-Workspace\",\"ExperimentName\":\"Mini-Tumor-Classification-AML_V1\",\"Definition\":{\"Configuration\":null,\"Attribution\":null,\"TelemetryValues\":{\"amlClientRequestId\":\"\",\"amlClientSessionId\":\"\",\"subscriptionId\":\"3bef7a06-fecc-47fc-ba25-a7899d62e16c\",\"maxConcurrentRuns\":1,\"maxTotalRuns\":20,\"tenantId\":\"\",\"maxDurationMinutes\":720,\"samplingMethod\":\"RANDOM\",\"computeTarget\":\"ComputeTarget\"},\"Overrides\":{\"Script\":\"hd_image_classification_dnn_driver.py\",\"UseAbsolutePath\":false,\"Arguments\":[\"--data-folder\",\"$AZUREML_DATAREFERENCE_default\",\"--labels-file-root\",\"$AZUREML_DATAREFERENCE_labels_file_root\"],\"SourceDirectoryDataStore\":null,\"Framework\":0,\"Target\":\"gpu-cluster\",\"DataReferences\":{},\"Data\":{},\"OutputData\":{},\"Datacaches\":[],\"JobName\":null,\"MaxRunDurationSeconds\":null,\"NodeCount\":1,\"InstanceTypes\":[],\"Priority\":null,\"CredentialPassthrough\":false,\"Identity\":null,\"Environment\":{\"Name\":\"AzureML-AutoML-DNN-Vision-GPU\",\"Version\":\"104\",\"AssetId\":\"azureml://registries/azureml/environments/AzureML-AutoML-DNN-Vision-GPU/versions/104\",\"AutoRebuild\":true,\"Python\":{\"InterpreterPath\":\"python\",\"UserManagedDependencies\":false,\"CondaDependencies\":{\"channels\":[\"conda-forge\",\"cerebis\"],\"dependencies\":[\"python=3.7\",\"pip=21.3.1\",\"numpy~=1.21.6\",\"libffi=3.3\",\"pycocotools=2.0.2\",\"shap=0.39.0\",\"recordclass=0.14.3\",\"llvmlite=0.36.0\",{\"pip\":[\"azureml-core==1.46.0\",\"azureml-mlflow==1.46.0\",\"azureml-dataset-runtime==1.46.0\",\"azureml-telemetry==1.46.0\",\"azureml-responsibleai==1.46.0\",\"azureml-automl-core==1.46.1.post1\",\"azureml-automl-runtime==1.46.1.post1\",\"azureml-train-automl-client==1.46.0\",\"azureml-defaults==1.46.0\",\"azureml-interpret==1.46.0\",\"azureml-train-automl-runtime==1.46.1.post1\",\"azureml-automl-dnn-vision==1.46.1\",\"azureml-dataprep>=2.24.4\"]}],\"name\":\"azureml_54a17edef71b712e10caf62b536f0b3b\"},\"BaseCondaEnvironment\":null},\"EnvironmentVariables\":{},\"Docker\":{\"BaseImage\":\"mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.1-cudnn8-ubuntu18.04:20221010.v1\",\"Platform\":{\"Os\":\"Linux\",\"Architecture\":\"amd64\"},\"BaseDockerfile\":null,\"BaseImageRegistry\":null,\"Enabled\":true,\"ShmSize\":\"16g\",\"Arguments\":[]},\"Spark\":{\"Repositories\":[],\"Packages\":[],\"PrecachePackages\":true},\"InferencingStackVersion\":null},\"History\":{\"OutputCollection\":true,\"DirectoriesToWatch\":null,\"EnableMLflowTracking\":false},\"Spark\":{\"Configuration\":{}},\"ParallelTask\":{\"MaxRetriesPerWorker\":0,\"WorkerCountPerNode\":1,\"TerminalExitCodes\":null,\"Configuration\":{}},\"BatchAi\":{\"NodeCount\":0},\"AmlCompute\":{\"Name\":null,\"VmSize\":null,\"RetainCluster\":false,\"ClusterMaxNodeCount\":null},\"AISuperComputer\":{\"InstanceType\":\"D2\",\"FrameworkImage\":null,\"ImageVersion\":null,\"Location\":null,\"AISuperComputerStorageData\":null,\"Interactive\":false,\"ScalePolicy\":null,\"VirtualClusterArmId\":null,\"TensorboardLogDirectory\":null,\"SSHPublicKey\":null,\"SSHPublicKeys\":null,\"EnableAzmlInt\":true,\"Priority\":\"Medium\",\"SLATier\":\"Standard\",\"UserAlias\":null},\"KubernetesCompute\":{\"InstanceType\":null},\"Tensorflow\":{\"WorkerCount\":0,\"ParameterServerCount\":0},\"Mpi\":{\"ProcessCountPerNode\":0},\"PyTorch\":{\"CommunicationBackend\":null,\"ProcessCount\":null},\"Hdi\":{\"YarnDeployMode\":0},\"ContainerInstance\":{\"Region\":null,\"CpuCores\":2.0,\"MemoryGb\":3.5},\"ExposedPorts\":null,\"Docker\":{\"UseDocker\":null,\"SharedVolumes\":null,\"ShmSize\":null,\"Arguments\":null},\"Cmk8sCompute\":{\"Configuration\":{}},\"CommandReturnCodeConfig\":{\"ReturnCode\":0,\"SuccessfulReturnCodes\":[]},\"EnvironmentVariables\":{\"AUTOML_SDK_RESOURCE_URL\":\"https://aka.ms/automl-resources/\"},\"ApplicationEndpoints\":{},\"Parameters\":[]},\"SnapshotId\":\"f198ffd7-eda6-4081-b201-09e01926471d\",\"Snapshots\":[],\"SourceCodeDataReference\":null,\"ParentRunId\":null,\"DataContainerId\":null,\"RunType\":null,\"DisplayName\":null,\"EnvironmentAssetId\":null,\"Properties\":{},\"Tags\":{},\"AggregatedArtifactPath\":null},\"ParentRunId\":\"busy_sun_x51p25t921_HD\"}', 'platform_config': '{\"ServiceAddress\":\"https://westeurope.api.azureml.ms\",\"SubscriptionId\":\"3bef7a06-fecc-47fc-ba25-a7899d62e16c\",\"ResourceGroupName\":\"Mini-Tumors-Germany\",\"WorkspaceName\":\"Mini-Tumors-Workspace\",\"ExperimentName\":\"Mini-Tumor-Classification-AML_V1\",\"Definition\":{\"Configuration\":null,\"Attribution\":null,\"TelemetryValues\":{\"amlClientRequestId\":\"\",\"amlClientSessionId\":\"\",\"subscriptionId\":\"3bef7a06-fecc-47fc-ba25-a7899d62e16c\",\"maxConcurrentRuns\":1,\"maxTotalRuns\":20,\"tenantId\":\"\",\"maxDurationMinutes\":720,\"samplingMethod\":\"RANDOM\",\"computeTarget\":\"ComputeTarget\"},\"Overrides\":{\"Script\":\"hd_image_classification_dnn_driver.py\",\"UseAbsolutePath\":false,\"Arguments\":[\"--data-folder\",\"$AZUREML_DATAREFERENCE_default\",\"--labels-file-root\",\"$AZUREML_DATAREFERENCE_labels_file_root\"],\"SourceDirectoryDataStore\":null,\"Framework\":0,\"Target\":\"gpu-cluster\",\"DataReferences\":{},\"Data\":{},\"OutputData\":{},\"Datacaches\":[],\"JobName\":null,\"MaxRunDurationSeconds\":null,\"NodeCount\":1,\"InstanceTypes\":[],\"Priority\":null,\"CredentialPassthrough\":false,\"Identity\":null,\"Environment\":{\"Name\":\"AzureML-AutoML-DNN-Vision-GPU\",\"Version\":\"104\",\"AssetId\":\"azureml://registries/azureml/environments/AzureML-AutoML-DNN-Vision-GPU/versions/104\",\"AutoRebuild\":true,\"Python\":{\"InterpreterPath\":\"python\",\"UserManagedDependencies\":false,\"CondaDependencies\":{\"channels\":[\"conda-forge\",\"cerebis\"],\"dependencies\":[\"python=3.7\",\"pip=21.3.1\",\"numpy~=1.21.6\",\"libffi=3.3\",\"pycocotools=2.0.2\",\"shap=0.39.0\",\"recordclass=0.14.3\",\"llvmlite=0.36.0\",{\"pip\":[\"azureml-core==1.46.0\",\"azureml-mlflow==1.46.0\",\"azureml-dataset-runtime==1.46.0\",\"azureml-telemetry==1.46.0\",\"azureml-responsibleai==1.46.0\",\"azureml-automl-core==1.46.1.post1\",\"azureml-automl-runtime==1.46.1.post1\",\"azureml-train-automl-client==1.46.0\",\"azureml-defaults==1.46.0\",\"azureml-interpret==1.46.0\",\"azureml-train-automl-runtime==1.46.1.post1\",\"azureml-automl-dnn-vision==1.46.1\",\"azureml-dataprep>=2.24.4\"]}],\"name\":\"azureml_54a17edef71b712e10caf62b536f0b3b\"},\"BaseCondaEnvironment\":null},\"EnvironmentVariables\":{},\"Docker\":{\"BaseImage\":\"mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.1-cudnn8-ubuntu18.04:20221010.v1\",\"Platform\":{\"Os\":\"Linux\",\"Architecture\":\"amd64\"},\"BaseDockerfile\":null,\"BaseImageRegistry\":null,\"Enabled\":true,\"ShmSize\":\"16g\",\"Arguments\":[]},\"Spark\":{\"Repositories\":[],\"Packages\":[],\"PrecachePackages\":true},\"InferencingStackVersion\":null},\"History\":{\"OutputCollection\":true,\"DirectoriesToWatch\":null,\"EnableMLflowTracking\":false},\"Spark\":{\"Configuration\":{}},\"ParallelTask\":{\"MaxRetriesPerWorker\":0,\"WorkerCountPerNode\":1,\"TerminalExitCodes\":null,\"Configuration\":{}},\"BatchAi\":{\"NodeCount\":0},\"AmlCompute\":{\"Name\":null,\"VmSize\":null,\"RetainCluster\":false,\"ClusterMaxNodeCount\":null},\"AISuperComputer\":{\"InstanceType\":\"D2\",\"FrameworkImage\":null,\"ImageVersion\":null,\"Location\":null,\"AISuperComputerStorageData\":null,\"Interactive\":false,\"ScalePolicy\":null,\"VirtualClusterArmId\":null,\"TensorboardLogDirectory\":null,\"SSHPublicKey\":null,\"SSHPublicKeys\":null,\"EnableAzmlInt\":true,\"Priority\":\"Medium\",\"SLATier\":\"Standard\",\"UserAlias\":null},\"KubernetesCompute\":{\"InstanceType\":null},\"Tensorflow\":{\"WorkerCount\":0,\"ParameterServerCount\":0},\"Mpi\":{\"ProcessCountPerNode\":0},\"PyTorch\":{\"CommunicationBackend\":null,\"ProcessCount\":null},\"Hdi\":{\"YarnDeployMode\":0},\"ContainerInstance\":{\"Region\":null,\"CpuCores\":2.0,\"MemoryGb\":3.5},\"ExposedPorts\":null,\"Docker\":{\"UseDocker\":null,\"SharedVolumes\":null,\"ShmSize\":null,\"Arguments\":null},\"Cmk8sCompute\":{\"Configuration\":{}},\"CommandReturnCodeConfig\":{\"ReturnCode\":0,\"SuccessfulReturnCodes\":[]},\"EnvironmentVariables\":{\"AUTOML_SDK_RESOURCE_URL\":\"https://aka.ms/automl-resources/\"},\"ApplicationEndpoints\":{},\"Parameters\":[]},\"SnapshotId\":\"f198ffd7-eda6-4081-b201-09e01926471d\",\"Snapshots\":[],\"SourceCodeDataReference\":null,\"ParentRunId\":null,\"DataContainerId\":null,\"RunType\":null,\"DisplayName\":null,\"EnvironmentAssetId\":null,\"Properties\":{},\"Tags\":{},\"AggregatedArtifactPath\":null},\"ParentRunId\":\"busy_sun_x51p25t921_HD\"}', '_aml_system_resume_child_runs': 'null', 'resume_child_runs': 'null', '_aml_system_all_jobs_generated': 'false', 'all_jobs_generated': 'false', '_aml_system_cancellation_requested': 'false', '_aml_system_progress_metadata_evaluation_timestamp': '\"2022-11-18T11:44:03.049114\"', '_aml_system_progress_metadata_digest': '\"e6295b741e0114185eaa4fd0ab83fae8dc4ad8def5ad805534173424d8d06a72\"', '_aml_system_progress_metadata_active_timestamp': '\"2022-11-18T11:44:03.049114\"', '_aml_system_optimizer_state_artifact': 'null', '_aml_system_outdated_optimizer_state_artifacts': '\"[]\"', '_aml_system_busy_sun_x51p25t921_HD_0': '{\"model\": {\"early_stopping\": \"True\", \"layers_to_freeze\": 0, \"learning_rate\": 0.01, \"model_name\": \"resnet50\", \"number_of_epochs\": 20, \"optimizer\": \"sgd\", \"weighted_loss\": 0}}', 'busy_sun_x51p25t921_HD_0': '{\"model\": {\"early_stopping\": \"True\", \"layers_to_freeze\": 0, \"learning_rate\": 0.01, \"model_name\": \"resnet50\", \"number_of_epochs\": 20, \"optimizer\": \"sgd\", \"weighted_loss\": 0}}', '_aml_system_busy_sun_x51p25t921_HD_1': '{\"model\": {\"early_stopping\": \"True\", \"layers_to_freeze\": 0, \"learning_rate\": 0.0001, \"model_name\": \"resnet152\", \"number_of_epochs\": 20, \"optimizer\": \"adamw\", \"weighted_loss\": 2}}', 'busy_sun_x51p25t921_HD_1': '{\"model\": {\"early_stopping\": \"True\", \"layers_to_freeze\": 0, \"learning_rate\": 0.0001, \"model_name\": \"resnet152\", \"number_of_epochs\": 20, \"optimizer\": \"adamw\", \"weighted_loss\": 2}}', '_aml_system_busy_sun_x51p25t921_HD_2': '{\"model\": {\"layers_to_freeze\": 0, \"learning_rate\": 0.01, \"model_name\": \"vitb16r224\", \"number_of_epochs\": 20, \"optimizer\": \"sgd\", \"weighted_loss\": 0}}', 'busy_sun_x51p25t921_HD_2': '{\"model\": {\"layers_to_freeze\": 0, \"learning_rate\": 0.01, \"model_name\": \"vitb16r224\", \"number_of_epochs\": 20, \"optimizer\": \"sgd\", \"weighted_loss\": 0}}'}, 'properties': {'_aml_system_scenario_identification': 'Remote.Child', 'iteration': '0', 'primary_metric_config': '{\"name\":\"accuracy\",\"goal\":\"maximize\"}', 'resume_from': 'null', 'runTemplate': 'HyperDrive', 'azureml.runsource': 'hyperdrive', 'platform': 'AML', 'ContentSnapshotId': 'f198ffd7-eda6-4081-b201-09e01926471d', 'user_agent': 'jasmine/c2231e359abf0fb7d62e74e03cb1302a18d8abd7', 'debug_flag': '{\"custom_optimizer_url\":null,\"custom_logger_url\":null,\"optimizer_settings\":null,\"priors\":null,\"early_failure_threshold\":null}', 'space_size': '84'}, 'id': '/subscriptions/3bef7a06-fecc-47fc-ba25-a7899d62e16c/resourceGroups/Mini-Tumors-Germany/providers/Microsoft.MachineLearningServices/workspaces/Mini-Tumors-Workspace/jobs/busy_sun_x51p25t921_HD', 'Resource__source_path': None, 'base_path': '/Users/louis.heath/Documents/School/mini-tumors/notebooks', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x142ffddc0>, 'serialize': <msrest.serialization.Serializer object at 0x142fb82b0>, 'sampling_algorithm': <azure.ai.ml.entities._job.sweep.sampling_algorithm.RandomSamplingAlgorithm object at 0x142ffdc70>, 'early_termination': <azure.ai.ml.entities._job.sweep.early_termination_policy.MedianStoppingPolicy object at 0x1095bec40>, 'limits': <azure.ai.ml.entities._job.job_limits.SweepJobLimits object at 0x142fb81f0>, 'search_space': {'model': <azure.ai.ml.entities._job.sweep.search_space.Choice object at 0x142ffde20>}, 'objective': <azure.ai.ml._restclient.v2022_10_01_preview.models._models_py3.Objective object at 0x142ffdb20>, 'display_name': 'nice_crayon_23hyg4z5', 'experiment_name': 'Mini-Tumor-Classification-AML_V1', 'compute': 'gpu-cluster', 'services': {'Studio': <azure.ai.ml._restclient.v2022_10_01_preview.models._models_py3.JobService object at 0x142ffdb50>}, 'inputs': {}, 'outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.busy_sun_x51p25t921_HD', 'mode': 'rw_mount'}}, 'trial': <azure.ai.ml.entities._job.parameterized_command.ParameterizedCommand object at 0x142ffddf0>, 'identity': None})"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View Trials inteface\n",
    "hd_job = ml_client.jobs.get(returned_job.name + \"_HD\")\n",
    "hd_job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WARNING: STILL DOING MULTILABEL HERE BY MISTAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1634852262026
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "name": "image-classification-multilabel-configuration",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Create the AutoML job with the related factory-function.\n",
    "\n",
    "image_classification_multilabel_job = automl.image_classification_multilabel(\n",
    "    compute=compute_name,\n",
    "    # name=\"dpv2-image-classif-multi-label-job-02\",\n",
    "    experiment_name=exp_name,\n",
    "    training_data=my_training_data_input,\n",
    "    validation_data=my_validation_data_input,\n",
    "    target_column_name=\"label\",\n",
    "    primary_metric=ClassificationMultilabelPrimaryMetrics.IOU,\n",
    "    tags={\"my_custom_tag\": \"My custom value\"},\n",
    ")\n",
    "\n",
    "image_classification_multilabel_job.set_limits(\n",
    "    timeout_minutes=60,\n",
    "    max_trials=10,\n",
    "    max_concurrent_trials=2,\n",
    ")\n",
    "\n",
    "image_classification_multilabel_job.extend_search_space(\n",
    "    [\n",
    "        SearchSpace(\n",
    "            model_name=Choice([\"vitb16r224\"]),\n",
    "            learning_rate=Uniform(0.005, 0.05),\n",
    "            number_of_epochs=Choice([15, 30]),\n",
    "            gradient_accumulation_step=Choice([1, 2]),\n",
    "        ),\n",
    "        SearchSpace(\n",
    "            model_name=Choice([\"seresnext\"]),\n",
    "            learning_rate=Uniform(0.005, 0.05),\n",
    "            # model-specific, valid_resize_size should be larger or equal than valid_crop_size\n",
    "            validation_resize_size=Choice([288, 320, 352]),\n",
    "            validation_crop_size=Choice([224, 256]),  # model-specific\n",
    "            training_crop_size=Choice([224, 256]),  # model-specific\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "image_classification_multilabel_job.set_sweep(\n",
    "    sampling_algorithm=\"Random\",\n",
    "    early_termination=BanditPolicy(\n",
    "        evaluation_interval=2, slack_factor=0.2, delay_evaluation=6\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1634852267930
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Submit the AutoML job\n",
    "returned_job = ml_client.jobs.create_or_update(\n",
    "    image_classification_multilabel_job\n",
    ")  # submit the job to the backend\n",
    "\n",
    "print(f\"Created job: {returned_job}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.jobs.stream(returned_job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When doing a hyperparameter sweep, it can be useful to visualize the different configurations that were tried using the HyperDrive UI. You can navigate to this UI by going to the 'Child jobs' tab in the UI of the main automl image job from above, which is the HyperDrive parent run. Then you can go into the 'Trials' tab of this HyperDrive parent run. Alternatively, here below you can see directly the HyperDrive parent run and navigate to its 'Trials' tab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd_job = ml_client.jobs.get(returned_job.name + \"_HD\")\n",
    "hd_job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Retrieve the Best Trial (Best Model's trial/run)\n",
    "Use the MLFLowClient to access the results (such as Models, Artifacts, Metrics) of a previously completed AutoML Trial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize MLFlow Client\n",
    "\n",
    "The models and artifacts that are produced by AutoML can be accessed via the MLFlow interface.\n",
    "Initialize the MLFlow client here, and set the backend as Azure ML, via. the MLFlow Client.\n",
    "\n",
    "IMPORTANT, you need to have installed the latest MLFlow packages with:\n",
    "\n",
    "    pip install azureml-mlflow\n",
    "\n",
    "    pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install azure-mlflow\n",
    "!pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# Obtain the tracking URL from MLClient\n",
    "MLFLOW_TRACKING_URI = ml_client.workspaces.get(\n",
    "    name=ml_client.workspace_name\n",
    ").mlflow_tracking_uri\n",
    "\n",
    "print(MLFLOW_TRACKING_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the MLFLOW TRACKING URI\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "\n",
    "print(\"\\nCurrent tracking uri: {}\".format(mlflow.get_tracking_uri()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking.client import MlflowClient\n",
    "\n",
    "# Initialize MLFlow client\n",
    "mlflow_client = MlflowClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the AutoML parent Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = returned_job.name\n",
    "\n",
    "# Example if providing an specific Job name/ID\n",
    "# job_name = \"salmon_camel_5sdf05xvb3\"\n",
    "\n",
    "# Get the parent run\n",
    "mlflow_parent_run = mlflow_client.get_run(job_name)\n",
    "\n",
    "print(\"Parent Run: \")\n",
    "print(mlflow_parent_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print parent run tags. 'automl_best_child_run_id' tag should be there.\n",
    "print(mlflow_parent_run.data.tags.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the AutoML best child run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model's child run\n",
    "\n",
    "best_child_run_id = mlflow_parent_run.data.tags[\"automl_best_child_run_id\"]\n",
    "print(\"Found best child run id: \", best_child_run_id)\n",
    "\n",
    "best_run = mlflow_client.get_run(best_child_run_id)\n",
    "\n",
    "print(\"Best child run: \")\n",
    "print(best_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get best model run's metrics\n",
    "Access the results (such as Models, Artifacts, Metrics) of a previously completed AutoML Run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(best_run.data.metrics, index=[0]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the best model locally\n",
    "Access the results (such as Models, Artifacts, Metrics) of a previously completed AutoML Run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create local folder\n",
    "import os\n",
    "\n",
    "local_dir = \"./artifact_downloads\"\n",
    "if not os.path.exists(local_dir):\n",
    "    os.mkdir(local_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download run's artifacts/outputs\n",
    "local_path = mlflow_client.download_artifacts(\n",
    "    best_run.info.run_id, \"outputs\", local_dir\n",
    ")\n",
    "print(\"Artifacts downloaded in: {}\".format(local_path))\n",
    "print(\"Artifacts: {}\".format(os.listdir(local_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Show the contents of the MLFlow model folder\n",
    "os.listdir(\"./artifact_downloads/outputs/mlflow-model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Register best model and deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Create managed online endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "from azure.ai.ml.entities import (\n",
    "    ManagedOnlineEndpoint,\n",
    "    ManagedOnlineDeployment,\n",
    "    Model,\n",
    "    Environment,\n",
    "    CodeConfiguration,\n",
    "    ProbeSettings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a unique endpoint name with current datetime to avoid conflicts\n",
    "import datetime\n",
    "\n",
    "online_endpoint_name = \"ic-ml-fridge-items-\" + datetime.datetime.now().strftime(\n",
    "    \"%m%d%H%M\"\n",
    ")\n",
    "\n",
    "# create an online endpoint\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=online_endpoint_name,\n",
    "    description=\"this is a sample online endpoint for deploying model\",\n",
    "    auth_mode=\"key\",\n",
    "    tags={\"foo\": \"bar\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.begin_create_or_update(endpoint).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Register best model and deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"ic-ml-fridge-items-model\"\n",
    "model = Model(\n",
    "    path=f\"azureml://jobs/{best_run.info.run_id}/outputs/artifacts/outputs/mlflow-model/\",\n",
    "    name=model_name,\n",
    "    description=\"my sample image classification multilabel model\",\n",
    "    type=AssetTypes.MLFLOW_MODEL,\n",
    ")\n",
    "\n",
    "# for downloaded file\n",
    "# model = Model(\n",
    "#     path=path=\"artifact_downloads/outputs/mlflow-model/\",\n",
    "#     name=model_name,\n",
    "#     description=\"my sample image classification multilabel model\",\n",
    "#     type=AssetTypes.MLFLOW_MODEL,\n",
    "# )\n",
    "\n",
    "registered_model = ml_client.models.create_or_update(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_model.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment = ManagedOnlineDeployment(\n",
    "    name=\"ic-ml-fridge-items-mlflow-dpl\",\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    model=registered_model.id,\n",
    "    instance_type=\"Standard_DS3_V2\",\n",
    "    instance_count=1,\n",
    "    liveness_probe=ProbeSettings(\n",
    "        failure_threshold=30,\n",
    "        success_threshold=1,\n",
    "        timeout=2,\n",
    "        period=10,\n",
    "        initial_delay=2000,\n",
    "    ),\n",
    "    readiness_probe=ProbeSettings(\n",
    "        failure_threshold=10,\n",
    "        success_threshold=1,\n",
    "        timeout=10,\n",
    "        period=10,\n",
    "        initial_delay=2000,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.online_deployments.begin_create_or_update(deployment).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ic ml fridge items deployment to take 100% traffic\n",
    "endpoint.traffic = {\"ic-ml-fridge-items-mlflow-dpl\": 100}\n",
    "ml_client.begin_create_or_update(endpoint).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get endpoint details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the details for online endpoint\n",
    "endpoint = ml_client.online_endpoints.get(name=online_endpoint_name)\n",
    "\n",
    "# existing traffic details\n",
    "print(endpoint.traffic)\n",
    "\n",
    "# Get the scoring URI\n",
    "print(endpoint.scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create request json\n",
    "import base64\n",
    "\n",
    "sample_image = \"./data/multilabelFridgeObjects/images/99.jpg\"\n",
    "\n",
    "\n",
    "def read_image(image_path):\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "request_json = {\n",
    "    \"input_data\": {\n",
    "        \"columns\": [\"image\"],\n",
    "        \"data\": [base64.encodebytes(read_image(sample_image)).decode(\"utf-8\")],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "request_file_name = \"sample_request_data.json\"\n",
    "\n",
    "with open(request_file_name, \"w\") as request_file:\n",
    "    json.dump(request_json, request_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = ml_client.online_endpoints.invoke(\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    deployment_name=deployment.name,\n",
    "    request_file=request_file_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize detections\n",
    "Now that we have scored a test image, we can visualize the prediction for this image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "IMAGE_SIZE = (18, 12)\n",
    "plt.figure(figsize=IMAGE_SIZE)\n",
    "img_np = mpimg.imread(sample_image)\n",
    "img = Image.fromarray(img_np.astype(\"uint8\"), \"RGB\")\n",
    "x, y = img.size\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(15, 15))\n",
    "# Display the image\n",
    "ax.imshow(img_np)\n",
    "prediction_list = json.loads(resp)\n",
    "prediction = prediction_list[0]\n",
    "score_threshold = 0.5\n",
    "\n",
    "label_offset_x = 30\n",
    "label_offset_y = 30\n",
    "for index, score in enumerate(prediction[\"probs\"]):\n",
    "    if score > score_threshold:\n",
    "        label = prediction[\"labels\"][index]\n",
    "        display_text = \"{} ({})\".format(label, round(score, 3))\n",
    "        print(display_text)\n",
    "\n",
    "        color = \"red\"\n",
    "        plt.text(label_offset_x, label_offset_y, display_text, color=color, fontsize=30)\n",
    "        label_offset_y += 30\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the deployment and endopoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.online_endpoints.begin_delete(name=online_endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Step: Load the best model and try predictions\n",
    "\n",
    "Loading the models locally assume that you are running the notebook in an environment compatible with the model. The list of dependencies that is expected by the model is specified in the MLFlow model produced by AutoML (in the 'conda.yaml' file within the mlflow-model folder).\n",
    "\n",
    "Since the AutoML model was trained remotelly in a different environment with different dependencies to your current local conda environment where you are running this notebook, if you want to load the model you have several options:\n",
    "\n",
    "1. A recommended way to locally load the model in memory and try predictions is to create a new/clean conda environment with the dependencies specified in the conda.yml file within the MLFlow model's folder, then use MLFlow to load the model and call .predict() as explained in the notebook **mlflow-model-local-inference-test.ipynb** in this same folder.\n",
    "\n",
    "2. You can install all the packages/dependencies specified in conda.yml into your current conda environment you used for using Azure ML SDK and AutoML. MLflow SDK also have a method to install the dependencies in the current environment. However, this option could have risks of package version conflicts depending on what's installed in your current environment.\n",
    "\n",
    "3. You can also use: mlflow models serve -m 'xxxxxxx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "You can see further examples of other AutoML tasks such as Regression, Image-Object-Detection, NLP-Text-Classification, Time-Series-Forcasting, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
